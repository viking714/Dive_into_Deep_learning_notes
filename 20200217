 这次笔记主要记录学习几个部分，分别是过拟合，欠拟合，梯度消失，梯度消失，梯度爆炸；语言处理部分（机器翻译，注意力机制，seq2seq和transformer）；图像处理部分（卷积，lenet，alexNet，VGGdeng）。
下面分别说一下。
  首先过拟合，欠拟合这个感觉掌握的还可以。现象是过拟合（训练集的准确率提升较大，而测试集提升不大，和训练集有较大差距），这个主要原因是因为模型过于复杂，对于已有的数据拟合的太好了造成的。
泛化能力不行。对新数据适应能力较差。解决方法可以有几个方面：1.增加训练数据量2.修改模型增加L1和L2正则，给模型认为增加一些噪音，让模型不太过拟合。至于欠拟合，
就是把模型调复杂，增加深度等方法。梯度消失和梯度爆炸在较深的模型会发生，对于梯度消失可以用lstm和rnn，对于梯度爆炸可以用梯度裁剪。
  语言处理这部分主要应用RNN（循环神经网络），好处就是增加了历史信息，在RNN中有几个比较常用的现在，LSTM和GRU这两个比较复杂。这部分我理解的不是特别好，有时间还得加强。
  图像处理部分，这个部分主要就是CNN（卷积神经网络），这部分网络较多，发展时间也比较久，LeNet，AlexNet，VGG等等。主要概念就是卷积核，池化，卷积的主要作用就是提取局部信息，当然
也可以起到降维的功能，不过降维主要还是池化层的作用。对于卷积层，通道，卷积核，步长这几个部分是比较重要的概念。卷积核的大小是一次选取局部的大小做抽象，通道分进通道和
出口通道，通常经过卷积尺寸会变小，相当于对图形做了抽象，而通道会变多，相当于按照不同角度去抽象图片。
